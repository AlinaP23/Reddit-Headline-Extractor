package reddit_feed_reader;

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.net.MalformedURLException;
import java.net.URL;
import java.net.URLConnection;


/**
 * Class that reads the Reddit RSS and saves them in one file per year.
 */
public class FeedReader {


	public static void main(String[] args){
		
		FeedReader fr = new FeedReader("C:/Users/Alina/Desktop/Data Mining/Projekt/newsFeed5.csv");
		long startTime = 1420070400;
		long endTime = 1421107199;
		fr.startReader(startTime, endTime);
	}
	
	private String generatedUrl; // the current concatenated URL
	private String pathToFile; // path to the file in which the reader writes the headlines
	private	long timestampBegin;
	private long timestampEnd;
	private BufferedReader rssReader; // reader for RSS files
	private BufferedWriter csvFileWriter; // writer that writes into the specified csv file
	private URL url; // URL object for getting the data
	
	/**
	 * Constructor
	 */
	public FeedReader(String pathToFile){
		this.pathToFile = pathToFile;
	}
	
	public void startReader(long startTime, long endTime){
				
		// do the following coding in a loop so that the URL changes day by day.
		// write the data in a file (this will be used for the data input in RapidMiner)
		
		
		timestampBegin = startTime;
		timestampEnd = startTime + (24*60*60) - 1; //seconds per day
		int i = 0;
		try {
			csvFileWriter = new BufferedWriter(new FileWriter(new File(pathToFile)));
		} catch (IOException e1) {
			// TODO Auto-generated catch block
			e1.printStackTrace();
		}
		
		do {
			String start = Long.toString(timestampBegin);
			String end = Long.toString(timestampEnd);
//			generatedUrl = "https://www.reddit.com/r/worldnews/search/.rss?q=timestamp:1420070400..1420156799&sort=top&restrict_sr=on&limit=5&syntax=cloudsearch";
			generatedUrl = "https://www.reddit.com/r/worldnews/search/.rss?q=timestamp:"
								+ start + ".." 
								+ end 
								+"&sort=top&restrict_sr=on&limit=5&syntax=cloudsearch";
			System.out.println("day " + i);
			try {
				url = new URL(generatedUrl);
				System.out.println(url);

				InputStream inputStream = url.openStream();
				InputStreamReader inputStreamReader = new InputStreamReader(inputStream);
				rssReader = new BufferedReader(inputStreamReader);
				
				// very important to do some preprocessing here (XML parser)...
					
				String readLineFromReddit;
				while(((readLineFromReddit = rssReader.readLine()) != null)){	
					csvFileWriter.write(readLineFromReddit);
				}
				
				System.out.println("DONE");
				
				
			} catch (MalformedURLException e) {
				// TODO error handling
				System.out.println("Malformed URL");
				e.printStackTrace();
				
			} catch (IOException e){
				// TODO error handling
				System.out.println("IOException");
				
			} finally {
				// close all streams
				
				try {
				 	rssReader.close();
							
				} catch (IOException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
			}
			i++;
			timestampBegin = timestampEnd + 1;
			timestampEnd = timestampBegin + (24*60*60) - 1;
		} while (timestampEnd < endTime);
		try {
			csvFileWriter.close();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}	
	}
}
